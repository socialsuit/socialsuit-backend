"""
Database Optimization Initialization Script
==========================================

This script initializes all database optimizations including:
- MongoDB indexes and aggregation pipelines
- PostgreSQL indexes and materialized views
- Redis cache warming
- Performance monitoring setup
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict, Any

from social_suit.app.services.database.mongodb_optimizer import MongoDBOptimizer
from social_suit.app.services.database.postgresql_optimizer import PostgreSQLOptimizer
from social_suit.app.services.database.query_optimizer import DatabaseOptimizer
from social_suit.app.services.database.redis import RedisManager
from social_suit.app.services.utils.logger_config import setup_logger

logger = setup_logger("database_optimization_init")

class DatabaseOptimizationInitializer:
    """
    Initializes all database optimizations across MongoDB, PostgreSQL, and Redis.
    """
    
    def __init__(self):
        self.mongodb_optimizer = MongoDBOptimizer()
        self.postgresql_optimizer = PostgreSQLOptimizer()
        self.database_optimizer = DatabaseOptimizer()
        self.redis_manager = RedisManager()
    
    async def initialize_all_optimizations(self) -> Dict[str, Any]:
        """
        Initialize all database optimizations.
        
        Returns:
            Dictionary containing initialization results
        """
        logger.info("Starting comprehensive database optimization initialization...")
        
        results = {
            "mongodb": {},
            "postgresql": {},
            "redis": {},
            "performance_monitoring": {},
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            # Initialize MongoDB optimizations
            logger.info("Initializing MongoDB optimizations...")
            results["mongodb"] = await self._initialize_mongodb()
            
            # Initialize PostgreSQL optimizations
            logger.info("Initializing PostgreSQL optimizations...")
            results["postgresql"] = await self._initialize_postgresql()
            
            # Initialize Redis optimizations
            logger.info("Initializing Redis optimizations...")
            results["redis"] = await self._initialize_redis()
            
            # Initialize performance monitoring
            logger.info("Initializing performance monitoring...")
            results["performance_monitoring"] = await self._initialize_performance_monitoring()
            
            logger.info("Database optimization initialization completed successfully!")
            
        except Exception as e:
            logger.error(f"Error during database optimization initialization: {str(e)}")
            results["error"] = str(e)
        
        return results
    
    async def _initialize_mongodb(self) -> Dict[str, Any]:
        """Initialize MongoDB optimizations."""
        results = {
            "indexes_created": [],
            "collections_optimized": [],
            "aggregation_pipelines": [],
            "cleanup_performed": False
        }
        
        try:
            # Create optimized indexes for all collections
            collections = [
                "analytics_data",
                "user_engagements", 
                "content_performance",
                "ab_tests",
                "scheduled_posts",
                "user_activity"
            ]
            
            for collection in collections:
                logger.info(f"Creating indexes for {collection}...")
                index_result = await self.mongodb_optimizer.create_optimized_indexes(collection)
                results["indexes_created"].extend(index_result.get("indexes", []))
                results["collections_optimized"].append(collection)
            
            # Test aggregation pipelines
            logger.info("Testing aggregation pipelines...")
            test_pipelines = [
                ("analytics_data", [{"$match": {"timestamp": {"$exists": True}}}, {"$limit": 1}]),
                ("content_performance", [{"$match": {"user_id": {"$exists": True}}}, {"$limit": 1}]),
                ("user_engagements", [{"$match": {"platform": {"$exists": True}}}, {"$limit": 1}])
            ]
            
            for collection, pipeline in test_pipelines:
                try:
                    await self.mongodb_optimizer.optimized_aggregate(collection, pipeline)
                    results["aggregation_pipelines"].append(f"{collection}_tested")
                except Exception as e:
                    logger.warning(f"Aggregation test failed for {collection}: {str(e)}")
            
            # Perform cleanup of old data (older than 1 year)
            logger.info("Performing data cleanup...")
            cleanup_result = await self.mongodb_optimizer.cleanup_old_data(days=365)
            results["cleanup_performed"] = cleanup_result
            
        except Exception as e:
            logger.error(f"MongoDB initialization error: {str(e)}")
            results["error"] = str(e)
        
        return results
    
    async def _initialize_postgresql(self) -> Dict[str, Any]:
        """Initialize PostgreSQL optimizations."""
        results = {
            "indexes_created": [],
            "tables_optimized": [],
            "materialized_views": [],
            "maintenance_performed": False,
            "statistics_updated": False
        }
        
        try:
            # Create optimized indexes for all tables
            tables = [
                "users",
                "scheduled_posts",
                "post_engagement",
                "user_metrics",
                "content_performance",
                "query_performance",
                "system_metrics",
                "ab_tests"
            ]
            
            for table in tables:
                logger.info(f"Creating indexes for {table}...")
                index_result = await self.postgresql_optimizer.create_optimized_indexes(table)
                results["indexes_created"].extend(index_result.get("indexes", []))
                results["tables_optimized"].append(table)
            
            # Create and refresh materialized views
            logger.info("Creating materialized views...")
            mv_result = await self.postgresql_optimizer.create_materialized_views()
            results["materialized_views"] = mv_result.get("views", [])
            
            # Update table statistics
            logger.info("Updating table statistics...")
            for table in tables:
                await self.postgresql_optimizer.analyze_table(table)
            results["statistics_updated"] = True
            
            # Perform table maintenance
            logger.info("Performing table maintenance...")
            maintenance_result = await self.postgresql_optimizer.perform_maintenance()
            results["maintenance_performed"] = maintenance_result.get("success", False)
            
        except Exception as e:
            logger.error(f"PostgreSQL initialization error: {str(e)}")
            results["error"] = str(e)
        
        return results
    
    async def _initialize_redis(self) -> Dict[str, Any]:
        """Initialize Redis optimizations."""
        results = {
            "cache_warmed": [],
            "patterns_configured": [],
            "memory_optimized": False
        }
        
        try:
            # Warm up frequently accessed caches
            logger.info("Warming up Redis caches...")
            
            # Cache common user data patterns
            cache_patterns = [
                "user_analytics_overview",
                "platform_insights", 
                "scheduled_posts_summary",
                "content_performance_metrics"
            ]
            
            for pattern in cache_patterns:
                try:
                    # Set up cache pattern configurations
                    await self.redis_manager.set(f"cache_config:{pattern}", {
                        "ttl": 3600,
                        "compression": True,
                        "serialization": "json"
                    })
                    results["patterns_configured"].append(pattern)
                except Exception as e:
                    logger.warning(f"Cache pattern setup failed for {pattern}: {str(e)}")
            
            # Configure Redis memory optimization
            logger.info("Configuring Redis memory optimization...")
            try:
                # Set memory policy and other optimizations
                memory_config = {
                    "maxmemory-policy": "allkeys-lru",
                    "maxmemory-samples": 5,
                    "timeout": 300
                }
                
                for key, value in memory_config.items():
                    await self.redis_manager.set(f"redis_config:{key}", value)
                
                results["memory_optimized"] = True
            except Exception as e:
                logger.warning(f"Redis memory optimization failed: {str(e)}")
            
        except Exception as e:
            logger.error(f"Redis initialization error: {str(e)}")
            results["error"] = str(e)
        
        return results
    
    async def _initialize_performance_monitoring(self) -> Dict[str, Any]:
        """Initialize performance monitoring."""
        results = {
            "monitoring_enabled": False,
            "metrics_configured": [],
            "alerts_configured": False
        }
        
        try:
            # Configure performance monitoring
            logger.info("Setting up performance monitoring...")
            
            # Set up query performance tracking
            monitoring_config = {
                "slow_query_threshold": 1000,  # 1 second
                "cache_hit_ratio_threshold": 0.8,  # 80%
                "memory_usage_threshold": 0.9,  # 90%
                "connection_pool_threshold": 0.8  # 80%
            }
            
            for metric, threshold in monitoring_config.items():
                await self.redis_manager.set(f"monitoring:{metric}", threshold)
                results["metrics_configured"].append(metric)
            
            results["monitoring_enabled"] = True
            
            # Configure basic alerting
            alert_config = {
                "email_notifications": False,
                "slack_notifications": False,
                "log_alerts": True
            }
            
            await self.redis_manager.set("alert_config", alert_config)
            results["alerts_configured"] = True
            
        except Exception as e:
            logger.error(f"Performance monitoring initialization error: {str(e)}")
            results["error"] = str(e)
        
        return results
    
    async def get_optimization_status(self) -> Dict[str, Any]:
        """
        Get current optimization status across all databases.
        
        Returns:
            Dictionary containing optimization status
        """
        logger.info("Checking optimization status...")
        
        status = {
            "mongodb": {},
            "postgresql": {},
            "redis": {},
            "overall_health": "unknown",
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            # MongoDB status
            mongodb_stats = await self.mongodb_optimizer.get_collection_stats()
            status["mongodb"] = {
                "collections": len(mongodb_stats),
                "total_documents": sum(stats.get("count", 0) for stats in mongodb_stats.values()),
                "total_size_mb": sum(stats.get("size", 0) for stats in mongodb_stats.values()) / (1024 * 1024),
                "indexes": sum(len(stats.get("indexes", [])) for stats in mongodb_stats.values())
            }
            
            # PostgreSQL status
            pg_stats = await self.postgresql_optimizer.get_table_sizes()
            status["postgresql"] = {
                "tables": len(pg_stats),
                "total_size_mb": sum(stats.get("size_mb", 0) for stats in pg_stats.values()),
                "indexes": "available"  # Would need specific query to count
            }
            
            # Redis status
            redis_info = await self.redis_manager.get_info()
            status["redis"] = {
                "memory_used_mb": redis_info.get("used_memory", 0) / (1024 * 1024),
                "keys": redis_info.get("db0", {}).get("keys", 0),
                "hit_rate": redis_info.get("keyspace_hits", 0) / max(1, redis_info.get("keyspace_hits", 0) + redis_info.get("keyspace_misses", 0))
            }
            
            # Determine overall health
            mongodb_healthy = status["mongodb"]["collections"] > 0
            postgresql_healthy = status["postgresql"]["tables"] > 0
            redis_healthy = status["redis"]["memory_used_mb"] > 0
            
            if mongodb_healthy and postgresql_healthy and redis_healthy:
                status["overall_health"] = "healthy"
            elif mongodb_healthy or postgresql_healthy:
                status["overall_health"] = "partial"
            else:
                status["overall_health"] = "unhealthy"
            
        except Exception as e:
            logger.error(f"Error checking optimization status: {str(e)}")
            status["error"] = str(e)
            status["overall_health"] = "error"
        
        return status
    
    async def run_maintenance(self) -> Dict[str, Any]:
        """
        Run maintenance tasks across all databases.
        
        Returns:
            Dictionary containing maintenance results
        """
        logger.info("Running database maintenance...")
        
        results = {
            "mongodb_maintenance": {},
            "postgresql_maintenance": {},
            "redis_maintenance": {},
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            # MongoDB maintenance
            logger.info("Running MongoDB maintenance...")
            results["mongodb_maintenance"] = await self.mongodb_optimizer.cleanup_old_data(days=90)
            
            # PostgreSQL maintenance
            logger.info("Running PostgreSQL maintenance...")
            results["postgresql_maintenance"] = await self.postgresql_optimizer.perform_maintenance()
            
            # Redis maintenance
            logger.info("Running Redis maintenance...")
            # Clear expired keys and optimize memory
            await self.redis_manager.flushdb()  # This would be more selective in production
            results["redis_maintenance"] = {"cache_cleared": True}
            
        except Exception as e:
            logger.error(f"Error during maintenance: {str(e)}")
            results["error"] = str(e)
        
        return results

# Convenience functions for easy initialization

async def initialize_database_optimizations():
    """Initialize all database optimizations."""
    initializer = DatabaseOptimizationInitializer()
    return await initializer.initialize_all_optimizations()

async def check_optimization_status():
    """Check current optimization status."""
    initializer = DatabaseOptimizationInitializer()
    return await initializer.get_optimization_status()

async def run_database_maintenance():
    """Run database maintenance tasks."""
    initializer = DatabaseOptimizationInitializer()
    return await initializer.run_maintenance()

if __name__ == "__main__":
    # Run initialization when script is executed directly
    async def main():
        logger.info("Starting database optimization initialization...")
        results = await initialize_database_optimizations()
        logger.info(f"Initialization completed: {results}")
        
        logger.info("Checking optimization status...")
        status = await check_optimization_status()
        logger.info(f"Optimization status: {status}")
    
    asyncio.run(main())