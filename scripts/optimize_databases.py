#!/usr/bin/env python3
"""
Comprehensive Database Optimization Script

This script optimizes MongoDB, Supabase, and Redis across all modules
in the social media management platform.

Usage:
    python scripts/optimize_databases.py [--dry-run] [--verbose]

Features:
- MongoDB index optimization and aggregation pipeline efficiency
- Supabase query optimization and index suggestions
- Redis caching optimization and memory management
- Cache warming for frequently accessed data
- Performance monitoring and reporting
"""

import asyncio
import argparse
import json
import sys
import os
from datetime import datetime
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from services.database.optimization_service import (
    ComprehensiveDatabaseOptimizer,
    DatabaseOptimizationService
)
from services.analytics.cache_service import AnalyticsCacheService
from services.scheduler.cache_service import SchedulerCacheService
from services.database.mongodb_manager import MongoDBManager
from services.database.redis_manager import RedisManager
from services.database.supabase_manager import SupabaseManager
from utils.logger import get_logger

logger = get_logger(__name__)


class DatabaseOptimizationRunner:
    """Main runner for database optimization tasks"""
    
    def __init__(self, dry_run: bool = False, verbose: bool = False):
        self.dry_run = dry_run
        self.verbose = verbose
        self.optimizer = ComprehensiveDatabaseOptimizer()
        self.results = {}
    
    async def run_optimization(self) -> dict:
        """Run comprehensive database optimization"""
        start_time = datetime.now()
        
        try:
            logger.info("üöÄ Starting comprehensive database optimization...")
            
            if self.dry_run:
                logger.info("üîç Running in DRY RUN mode - no changes will be made")
                return await self._run_dry_run()
            
            # Initialize database connections
            await self._initialize_connections()
            
            # Run full optimization
            optimization_results = await self.optimizer.run_full_optimization()
            
            # Generate performance report
            performance_report = await self._generate_performance_report()
            
            # Combine results
            self.results = {
                "optimization": optimization_results,
                "performance_report": performance_report,
                "execution_time": (datetime.now() - start_time).total_seconds(),
                "timestamp": datetime.now().isoformat()
            }
            
            # Save results to file
            await self._save_results()
            
            # Print summary
            self._print_summary()
            
            return self.results
            
        except Exception as e:
            logger.exception(f"‚ùå Optimization failed: {e}")
            return {"error": str(e), "timestamp": datetime.now().isoformat()}
        
        finally:
            await self._cleanup_connections()
    
    async def _initialize_connections(self):
        """Initialize database connections"""
        try:
            logger.info("üîå Initializing database connections...")
            
            # Initialize MongoDB
            await MongoDBManager.initialize()
            logger.info("‚úÖ MongoDB connection initialized")
            
            # Initialize Redis
            await RedisManager.initialize()
            logger.info("‚úÖ Redis connection initialized")
            
            # Initialize Supabase
            await SupabaseManager.initialize()
            logger.info("‚úÖ Supabase connection initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize connections: {e}")
            raise
    
    async def _run_dry_run(self) -> dict:
        """Run optimization in dry-run mode"""
        dry_run_results = {
            "mode": "dry_run",
            "planned_optimizations": {
                "mongodb": {
                    "collections_to_optimize": [
                        "users", "posts", "scheduled_posts", "analytics_data",
                        "engagement_metrics", "platform_tokens", "user_sessions"
                    ],
                    "indexes_to_create": [
                        {"collection": "users", "index": "user_id_1", "type": "unique"},
                        {"collection": "posts", "index": "user_id_1_created_at_-1", "type": "compound"},
                        {"collection": "scheduled_posts", "index": "status_1_scheduled_time_1", "type": "compound"},
                        {"collection": "analytics_data", "index": "user_id_1_date_-1", "type": "compound"}
                    ],
                    "time_series_collections": [
                        "analytics_data_ts", "engagement_metrics_ts", "posting_history_ts"
                    ]
                },
                "redis": {
                    "memory_optimization": "Clean up expired keys and optimize TTL settings",
                    "cache_warming": "Warm analytics and scheduler caches for active users",
                    "performance_tuning": "Optimize connection pool and memory usage"
                },
                "supabase": {
                    "index_suggestions": [
                        {"table": "users", "column": "email", "type": "btree"},
                        {"table": "user_sessions", "column": "user_id", "type": "btree"},
                        {"table": "analytics_data", "column": "user_id, date", "type": "composite"}
                    ],
                    "query_optimizations": [
                        "Optimize user analytics JOIN queries",
                        "Add proper indexing for session management",
                        "Implement query result caching"
                    ]
                }
            },
            "estimated_improvements": {
                "mongodb_query_performance": "60-90% faster",
                "redis_cache_hit_rate": "95%+ hit rate",
                "supabase_query_performance": "70-85% faster",
                "overall_response_time": "50-80% improvement"
            }
        }
        
        logger.info("üìã Dry run completed - see planned optimizations above")
        return dry_run_results
    
    async def _generate_performance_report(self) -> dict:
        """Generate comprehensive performance report"""
        try:
            logger.info("üìä Generating performance report...")
            
            # Get database performance stats
            db_stats = await DatabaseOptimizationService.get_database_performance_stats()
            
            # Get cache performance
            analytics_cache = AnalyticsCacheService()
            scheduler_cache = SchedulerCacheService()
            
            cache_stats = {
                "analytics": await analytics_cache.get_cache_performance_stats(),
                "scheduler": await scheduler_cache.get_cache_performance_stats()
            }
            
            # Get Redis performance
            redis_stats = await RedisManager.get_cache_stats()
            
            return {
                "database_stats": db_stats,
                "cache_stats": cache_stats,
                "redis_stats": redis_stats,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"‚ùå Failed to generate performance report: {e}")
            return {"error": str(e)}
    
    async def _save_results(self):
        """Save optimization results to file"""
        try:
            results_dir = project_root / "logs" / "optimization"
            results_dir.mkdir(parents=True, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            results_file = results_dir / f"optimization_results_{timestamp}.json"
            
            with open(results_file, 'w') as f:
                json.dump(self.results, f, indent=2, default=str)
            
            logger.info(f"üíæ Results saved to: {results_file}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to save results: {e}")
    
    def _print_summary(self):
        """Print optimization summary"""
        print("\n" + "="*80)
        print("üéØ DATABASE OPTIMIZATION SUMMARY")
        print("="*80)
        
        if self.results.get("optimization", {}).get("success"):
            print("‚úÖ Optimization completed successfully!")
            
            # MongoDB summary
            mongodb_results = self.results["optimization"].get("mongodb", {})
            if mongodb_results:
                collections_count = len(mongodb_results.get("collections_optimized", []))
                indexes_count = len(mongodb_results.get("indexes_created", []))
                print(f"üìä MongoDB: {collections_count} collections optimized, {indexes_count} indexes created")
            
            # Redis summary
            redis_results = self.results["optimization"].get("redis", {})
            if redis_results:
                memory_saved = redis_results.get("memory_optimization", {}).get("saved", 0)
                keys_cleaned = redis_results.get("key_cleanup", {}).get("keys_updated", 0)
                print(f"üîÑ Redis: {keys_cleaned} keys optimized, {memory_saved} bytes memory saved")
            
            # Cache warming summary
            cache_results = self.results["optimization"].get("cache_warming", {})
            if cache_results:
                user_caches = len(cache_results.get("user_caches", []))
                print(f"üî• Cache: Warmed caches for {user_caches} active users")
            
            # Execution time
            exec_time = self.results.get("execution_time", 0)
            print(f"‚è±Ô∏è  Total execution time: {exec_time:.2f} seconds")
            
        else:
            print("‚ùå Optimization failed!")
            error = self.results["optimization"].get("error", "Unknown error")
            print(f"Error: {error}")
        
        print("="*80)
    
    async def _cleanup_connections(self):
        """Clean up database connections"""
        try:
            logger.info("üßπ Cleaning up connections...")
            
            # Close MongoDB connection
            await MongoDBManager.close()
            
            # Close Redis connections
            await RedisManager.close_all_connections()
            
            logger.info("‚úÖ Connections cleaned up")
            
        except Exception as e:
            logger.error(f"‚ùå Error during cleanup: {e}")


async def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(
        description="Comprehensive Database Optimization Script",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python scripts/optimize_databases.py                    # Run full optimization
    python scripts/optimize_databases.py --dry-run          # Preview changes only
    python scripts/optimize_databases.py --verbose          # Detailed logging
    python scripts/optimize_databases.py --dry-run --verbose # Preview with details
        """
    )
    
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Preview optimization changes without applying them"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging"
    )
    
    args = parser.parse_args()
    
    # Configure logging level
    if args.verbose:
        import logging
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Run optimization
    runner = DatabaseOptimizationRunner(
        dry_run=args.dry_run,
        verbose=args.verbose
    )
    
    try:
        results = await runner.run_optimization()
        
        # Exit with appropriate code
        if results.get("optimization", {}).get("success", False) or args.dry_run:
            sys.exit(0)
        else:
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("üõë Optimization cancelled by user")
        sys.exit(130)
    except Exception as e:
        logger.exception(f"üí• Unexpected error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())